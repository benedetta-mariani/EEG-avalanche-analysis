{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "658dce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ava_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d878c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## rigettando anche sulla base del ppp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e751f9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.chdir('../../../Desktop/Criticality in barrel cortex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed66101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from power import *\n",
    "##from powerlaw_fit import *\n",
    "#from stats import *\n",
    "import matplotlib.cm as cm\n",
    "cmap = cm.tab10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a4ba237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf\n",
    "def x_autocorr_sm(x_data,nrep = 100, q = [2.5,97.5]):\n",
    "    '''\n",
    "    autocorrelation using statsmodels.\n",
    "    faster for longer timeseries dueto use of fft\n",
    "    - x_data timeseries\n",
    "    - nrep, int, number of random realizations for null model \n",
    "    - q, percentiles for error\n",
    "\n",
    "    Support: tau= 1,2,...,N/2 where N=len(x_data)\n",
    "    '''\n",
    "\n",
    "    N = int( len(x_data)/2 )\n",
    "    x = np.arange(N+1)\n",
    "    y = acf(x_data,fft=True,nlags=N)\n",
    "    \n",
    "    N = int( len(x_data)/2 )\n",
    "    x = np.arange(N+1)\n",
    "    y_original = np.zeros((nrep,N+1))\n",
    "    \n",
    "    for i_nrep in range(nrep):\n",
    "        ## periodic boundary conditions with randomly selected starting point\n",
    "        i_rand = np.random.randint(N)\n",
    "        x_data_i = np.append(x_data[i_rand:],x_data[:i_rand])\n",
    "        y_original[i_nrep,:] = acf(x_data_i,fft=True,nlags=N)#[1:]\n",
    "\n",
    "    \n",
    "    y_mu = np.mean(y_original,axis=0)\n",
    "    y_1,y_2 = np.percentile(y_original,q=q,axis=0)\n",
    "    result = {}\n",
    "    result['tau'] = x\n",
    "    result['C'] = np.array([y_mu,y_1,y_2])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46d98ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr(x, y_mu, y_1,y_2, y_mu_rand, y_1_rand,y_2_rand, tau_star):\n",
    "    plt.rcParams['font.size'] = 18\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1)#, figsize=fig_size)\n",
    "    lw = 2\n",
    "    alpha_val = .5\n",
    "    ## Plot the empirical autocorrelation\n",
    "    x_ = x\n",
    "    y_ = y_mu\n",
    "    z1_ = y_1\n",
    "    z2_ = y_2\n",
    "    c_ = cmap(0)\n",
    "    ax.plot(x_,y_,c = c_,lw=lw, label = 'Data')\n",
    "    ax.fill_between(x_,z1_,z2_,color=c_,alpha=alpha_val,lw=0)\n",
    "\n",
    "\n",
    "\n",
    "    ## Plot the randomized autocorrelation\n",
    "    x_ = x\n",
    "    y_ = y_mu_rand\n",
    "    z1_ = y_1_rand\n",
    "    z2_ = y_2_rand\n",
    "    c_ = cmap(1)\n",
    "    ax.plot(x_,y_,c = c_,lw=lw, label = 'Randomized')\n",
    "    ax.fill_between(x_,z1_,z2_,color=c_,alpha=alpha_val,lw=0)\n",
    "\n",
    "\n",
    "    ax.plot([tau_star,tau_star],[-1,1],lw=1,color='black',ls=':')\n",
    "\n",
    "\n",
    "    ## Layout stuff\n",
    "    ax.legend(loc='upper right')\n",
    "\n",
    "    ax.set_xscale('log')\n",
    "    # ax.set_yscale('log')\n",
    "\n",
    "    ax.set_xlabel(r'Time Lag, $\\tau$')#,labelpad=0)\n",
    "    ax.set_ylabel(r'$C(\\tau)$')\n",
    "    ax.set_ylim(-0.1,0.3)\n",
    "\n",
    "\n",
    "    x_annot_tau = 0.8\n",
    "    y_annot_tau = 0.6\n",
    "    ax.annotate(r'$\\tau^*=%s$'%(int(tau_star)),xy=(x_annot_tau,y_annot_tau),xycoords = 'axes fraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30703d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_autocorr_sm_ext(x_data,nrep = 100, q = [2.5,97.5]):\n",
    "    '''\n",
    "    autocorrelation using statsmodels.\n",
    "    faster for longer timeseries dueto use of fft\n",
    "    - x_data timeseries\n",
    "    - nrep, int, number of random realizations for null model \n",
    "    - q, percentiles for error\n",
    "\n",
    "    Support: tau= 1,2,...,N/2 where N=len(x_data)\n",
    "    '''\n",
    "\n",
    "    N = int( len(x_data)/2 )\n",
    "    x = np.arange(N+1)\n",
    "    y_original = np.zeros((nrep,N+1))\n",
    "    y_random = np.zeros((nrep,N+1))\n",
    "    for i_nrep in range(nrep):\n",
    "        ## periodic boundary conditions with randomly selected starting point\n",
    "        i_rand = np.random.randint(N)\n",
    "        x_data_i = np.append(x_data[i_rand:],x_data[:i_rand])\n",
    "        y_original[i_nrep,:] = acf(x_data_i,fft=True,nlags=N)#[1:]\n",
    "\n",
    "        ## randomize\n",
    "        np.random.shuffle(x_data_i)\n",
    "        y_random[i_nrep,:] =  acf(x_data_i,fft=True,nlags=N)#[1:]\n",
    "\n",
    "\n",
    "    y_mu = np.mean(y_original,axis=0)\n",
    "    y_1,y_2 = np.percentile(y_original,q=q,axis=0)\n",
    "\n",
    "    y_mu_rand = np.mean(y_random,axis=0)\n",
    "    y_1_rand,y_2_rand = np.percentile(y_random,q=q,axis=0)\n",
    "\n",
    "    result = {}\n",
    "    result['tau'] = x\n",
    "    result['C'] = [y_mu,y_1,y_2]\n",
    "    result['C_rand'] = [y_mu_rand,y_1_rand,y_2_rand]\n",
    "    result['tmp'] = [y_original,y_random]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e4ca6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benedetta\\Downloads\\NewbornEEGData-20220203T094950Z-001\\NewbornEEGData\n"
     ]
    }
   ],
   "source": [
    "cd \"../../../Downloads/NewbornEEGData-20220203T094950Z-001/NewbornEEGData/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e2e116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import powerlaw as pwl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed9be5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_sub = np.array([ 5,  6,  9, 11, 12, 16, 17, 18, 19, 23, 30, 33, 35, 37, 40, 45, 47,\n",
    "       49, 52, 56, 58, 62, 66, 67, 68, 71, 14, 22, 27, 41, 46, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68cdd9f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22, 23, 13, 2, 29, 3, 4, 16, 5, 7, 27, 19]\n"
     ]
    }
   ],
   "source": [
    "## ORDER OF THE LANGUAGES\n",
    "order = pd.read_excel('../../../Downloads/ordine lingue.xlsx')#1 en, 2 fr, 3 sp\n",
    "\n",
    "\n",
    "subject_french = order[order[\"last language\"]==2][\"subject\"].values\n",
    "\n",
    "subject_en = order[order[\"last language\"]==1][\"subject\"].values\n",
    "\n",
    "subject_span = order[order[\"last language\"]==3][\"subject\"].values\n",
    "\n",
    "sub_fren = (list(set(subject_french) & set(good_sub)))\n",
    "sub_span = (list(set(subject_span) & set(good_sub)))\n",
    "sub_en = (list(set(subject_en) & set(good_sub)))\n",
    "\n",
    "\n",
    "good_sub = np.asarray(good_sub)\n",
    "\n",
    "#index. = np.where()\n",
    "\n",
    "type(good_sub)\n",
    "\n",
    "h = []\n",
    "for k in sub_fren:\n",
    "    #if k in good_sub:\n",
    "    #h.append(np.where(k == good_sub)[0])\n",
    "    h.append(good_sub.tolist().index(k))\n",
    "print(h)        \n",
    "#np.concatenate(h)\n",
    "\n",
    "ll = np.concatenate([np.where(good_sub==i)[0] for i in sub_fren])\n",
    "\n",
    "ll\n",
    "\n",
    "def funct(sub, vec1, vec2):\n",
    "    index = np.concatenate([np.where(good_sub==i)[0] for i in sub])\n",
    "    #index = np.where(good_sub, sub_fren)\n",
    "    al1 = vec1[index]\n",
    "    al2 = vec2[index]\n",
    "    print(stats.ttest_rel(al1, al2,alternative = 'less') )\n",
    "    \n",
    "    \n",
    "\n",
    "def funct2(sub, vec1):\n",
    "    index = np.concatenate([np.where(good_sub==i)[0] for i in sub])\n",
    "    #index = np.where(good_sub, sub_fren)\n",
    "    al1 = vec1[index]\n",
    "    #al2 = vec2[index]\n",
    "    return al1\n",
    "    #print(stats.ttest_rel(al1, al2,alternative = 'less') )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a3d4e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import scipy.signal\n",
    "from scipy.signal import argrelextrema\n",
    "from scipy.optimize import curve_fit\n",
    "from statsmodels.tsa.stattools import acf, ccf\n",
    "def monoExp(t, tau, a):\n",
    "    \"\"\"\n",
    "    Exponetial function, starting at 1 in t = 0.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    t : numpy.ndarray\n",
    "        Time.\n",
    "    tau : float\n",
    "        Autocorrelation time.\n",
    "    a : float\n",
    "        Scale factor.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Exponential function.\n",
    "    \"\"\"\n",
    "    return a*(np.exp(-t/tau) - 1) + 1\n",
    "\n",
    "\n",
    "def monoExp2(t, tau, a):\n",
    "    \"\"\"\n",
    "    Exponetial function, starting at 1 in t = 0.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    t : numpy.ndarray\n",
    "        Time.\n",
    "    tau : float\n",
    "        Autocorrelation time.\n",
    "    a : float\n",
    "        Scale factor.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Exponential function.\n",
    "    \"\"\"\n",
    "    return -(a*(np.exp(-t/tau) - 1) +1)\n",
    "\n",
    "def fit_envelope_autocorr(data, delta_t = 0.002):\n",
    "    \"\"\"\n",
    "    Fit the exponential envelope of the autocorrelation function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    autocorr : numpy.ndarray\n",
    "        Autocorrelation functions. Each row is the autocorrelation\n",
    "        for a given channel.\n",
    "    delta_t : float, optional\n",
    "        Sampling time of the experimental signals.\n",
    "        The default is 0.002s.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tcorr : numpy.ndarray\n",
    "        Autocorrelation times for each channel.\n",
    "    \"\"\"\n",
    "\n",
    "    maxima = argrelextrema(data, np.greater, order = 100)[0]\n",
    "    minima = argrelextrema(data, np.less, order = 100)[0]\n",
    "\n",
    "    x_to_fit = np.insert(maxima,0,0)\n",
    "    g = data[maxima]\n",
    "    y_to_fit = np.insert(g,0,1)\n",
    "    params_max, _ = curve_fit(monoExp, x_to_fit, y_to_fit, (250, 1))\n",
    "    #print(params_max)\n",
    "    \n",
    "\n",
    "    \n",
    "    x_to_fit = np.insert(minima,0,0)\n",
    "    g = data[minima]\n",
    "    y_to_fit = np.insert(g,0,-1)\n",
    "    \n",
    "    params_min, _ = curve_fit(monoExp, x_to_fit, y_to_fit, (250, 1))\n",
    "    #print(params_min)\n",
    "    \n",
    "    tcorr = (params_max[0] + params_min[0])/2*delta_t\n",
    "            \n",
    "    return tcorr\n",
    "#params_max[0]*delta_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "731c5bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.insert(np.array([1,2,3]),0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3a1d0c",
   "metadata": {},
   "source": [
    "## EEg DFA analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc805c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMPARISON BETWEEN SILENCE1 AND SILENCE2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.signal as ss\n",
    "import scipy.io\n",
    "#from dfa_functions import *\n",
    "ch_names = ['F7', 'F3', 'Fz', 'F4', 'F8', 'T7', 'C3', 'Cz', 'C4', 'T8']\n",
    "ch_names = np.array(ch_names)\n",
    "subjs  = [5,6,9,11,12,13,16,17,18,19,21,23,24,25,30,33,34,35,37,39,40,45,47,49,52,53,56,57,58,60,62,63,65,66,67,68,69,71,14,20,22,27,28,29,31,41,46,64,70]\n",
    "## you can discard subjec t 23 and 24\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import welch\n",
    "import pandas as pd\n",
    "import mne\n",
    "\n",
    "\n",
    "ch_names = np.array(ch_names)\n",
    "sfreq = 500\n",
    "info = mne.create_info(ch_names = list(ch_names),\n",
    "                       ch_types = 'eeg',\n",
    "                       sfreq = sfreq)\n",
    "def find_bad_channels(data, MAX_PEAK=200, MAX_PEAK_SIGMA=15, MAX_DIST_PS=4.5e-3, OFFSET=30, fmin=1, fmax=100, \n",
    "                      verbose = True):\n",
    "    idx_down, idx_up = 0, data.shape[1]\n",
    "    ss = np.std(data)\n",
    "    \n",
    "    psds, freqs = mne.time_frequency.psd_welch(mne.io.RawArray(data/1e6, info, verbose=False), fmin=fmin, fmax=fmax, n_fft=2048, n_overlap=1024/2, verbose=False)\n",
    "    psds = np.log10(psds)\n",
    "    \n",
    "    dist = [((tmp-psds.mean(axis=0))**2).sum() for tmp in psds]\n",
    "    dist = np.array(dist) / (psds**2).sum() * 1e2\n",
    "    \n",
    "    rej = []\n",
    "    for i, ch in enumerate(ch_names):\n",
    "        delta = np.abs(data[i]).max()\n",
    "    \n",
    "        str_rej = str()\n",
    "\n",
    "        if delta>MAX_PEAK or dist[i]>MAX_DIST_PS:\n",
    "            rej.append(ch)\n",
    "            str_rej = '-> rejected'\n",
    "            str_rej += ' ('\n",
    "            if delta>MAX_PEAK:\n",
    "                str_rej += ' peak'\n",
    "                idx = np.where(np.abs(data[i])>MAX_PEAK)[0]\n",
    "            \n",
    "            if dist[i]>MAX_DIST_PS:\n",
    "                str_rej += ' ps'\n",
    "            str_rej += ')'\n",
    "            \n",
    "        if verbose: print(f'* {ch}: max peak = {np.round(delta, 2)} mV ({np.round(delta/ss, 2)} std); dist ps = {np.round(dist[i],3)} '+str_rej)\n",
    "        \n",
    "        if delta>MAX_PEAK:\n",
    "            if np.max(idx)/sfreq<OFFSET:\n",
    "                idx_down = np.max([np.max(idx),idx_down])\n",
    "                if verbose: print(f'[*] WARNING: Peak only in the initial part - time: {np.max(idx)/sfreq} s')\n",
    "            if np.min(idx)/sfreq>180-OFFSET: ##elif??\n",
    "                idx_up = np.min([np.min(idx),idx_up])\n",
    "                if verbose: print(f'[*] WARNING: Peak only in the last part - time: {np.min(idx)/sfreq} s')\n",
    "    if verbose: print('\\nBad channels:', rej, '\\n')\n",
    "    return rej, idx_down, idx_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b18173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  diceva di controllare time scales david poeppel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4000051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMPARISON BETWEEN SILENCE1 AND SILENCE2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.signal as ss\n",
    "import scipy.io\n",
    "from dfa_functions import *\n",
    "\n",
    "overlap =0.5\n",
    "bands = [[1,3],[4,8],[8,13],[14,30],[31,60]]\n",
    "labels = ['band-1', 'band-2', 'band-3', 'band-4', 'band-5']\n",
    "subjs  = [5,6,9,11,12,13,16,17,18,19,21,23,24,25,30,33,34,35,37,39,40,45,47,49,52,53,56,57,58,60,62,63,65,66,67,68,69,71,14,20,22,27,28,29,31,41,46,64,70]\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import welch\n",
    "import pandas as pd\n",
    "import mne\n",
    "\n",
    "hh = 14 ## checl varying also hh, questo lo posso fare a posteriori e mi sa che lo avevo fatto, quindi era robusto\n",
    "ch_names = ['F7', 'F3', 'Fz', 'F4', 'F8', 'T7', 'C3', 'Cz', 'C4', 'T8']\n",
    "ch_names = np.array(ch_names)\n",
    "sfreq = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d63b372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dfa_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdaa273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180.286\n",
      "188.766\n",
      "saving\n",
      "180.236\n",
      "188.316\n",
      "saving\n",
      "180.27\n",
      "189.194\n",
      "saving\n",
      "180.272\n",
      "189.74\n",
      "saving\n",
      "180.322\n",
      "189.458\n",
      "saving\n",
      "180.288\n",
      "188.45\n",
      "180.32\n",
      "189.32\n",
      "saving\n",
      "180.238\n",
      "186.714\n",
      "saving\n",
      "180.274\n",
      "187.092\n",
      "saving\n",
      "180.278\n",
      "189.276\n",
      "saving\n",
      "180.284\n",
      "188.636\n",
      "180.266\n",
      "189.13\n",
      "saving\n",
      "180.25\n",
      "190.528\n",
      "180.324\n",
      "187.892\n",
      "180.288\n",
      "189.442\n",
      "saving\n",
      "180.246\n",
      "194.122\n",
      "saving\n",
      "180.25\n",
      "188.17\n",
      "180.354\n",
      "188.032\n",
      "saving\n",
      "180.246\n",
      "188.344\n",
      "saving\n",
      "180.322\n",
      "190.292\n",
      "180.33\n",
      "188.484\n",
      "saving\n",
      "180.274\n",
      "189.766\n",
      "saving\n",
      "180.262\n",
      "207.378\n",
      "saving\n",
      "180.32\n",
      "201.342\n"
     ]
    }
   ],
   "source": [
    "DFA_1 =[[] for i in range(len(good_sub))]\n",
    "DFA_2 =[[] for i in range(len(good_sub))]\n",
    "o = 0\n",
    "for i, subj in enumerate(subjs):\n",
    "    dfa_sil_params = [[] for r in range(len(bands)-1)]\n",
    "    dfa_sil2_params = [[] for r in range(len(bands)-1)]\n",
    "    #print(f'\\n\\n########## SUBJ {subj} ({i+1}/{len(subjs)})##########')\n",
    "    s1 = loadmat(f'BB{subj}_Filtered (1-100)/Silence (500)/BB{subj} silence1 (continuous).mat')\n",
    "    s2 = loadmat(f'BB{subj}_Filtered (1-100)/Silence (500)/BB{subj} silence2 (continuous).mat')\n",
    "    \n",
    "    \n",
    "    data = s1['eeg_rest'].astype('float')\n",
    "    print(data.shape[1]/500)\n",
    "    rej, idx_down, idx_up = find_bad_channels(data, verbose = False)\n",
    "    if idx_down > 0 or idx_up < data.shape[1]:\n",
    "        if idx_down > 0:\n",
    "            idx_down +=1\n",
    "        if idx_up < data.shape[1]:\n",
    "            idx_up -= 1\n",
    "        data = data[:,idx_down:idx_up]\n",
    "        rej, idx_down, idx_up = find_bad_channels(data, verbose = False)\n",
    "    idx_accepted = np.sort([np.where(ch_names == i)[0][0] for i in list(set(ch_names) - set(rej))])\n",
    "    data = data[list(idx_accepted), idx_down:idx_up][:, :71463] #try\n",
    "    nchan = data.shape[0]\n",
    "    \n",
    "    data2 = s2['eeg_rest'].astype('float')\n",
    "    print(data2.shape[1]/500)\n",
    "    rej, idx_down, idx_up = find_bad_channels(data2, verbose = False)\n",
    "    if idx_down > 0 or idx_up < data2.shape[1]:\n",
    "        if idx_down > 0:\n",
    "            idx_down +=1\n",
    "        if idx_up < data2.shape[1]:\n",
    "            idx_up -= 1\n",
    "        data2 = data2[:,idx_down:idx_up]\n",
    "        rej, idx_down, idx_up = find_bad_channels(data2, verbose = False)\n",
    "    idx_accepted = np.sort([np.where(ch_names == i)[0][0] for i in list(set(ch_names) - set(rej))])\n",
    "    data2 = data2[list(idx_accepted), idx_down:idx_up][:, :71463] #try #  questo lo posso modificare solo da qui\n",
    "    nchan2 = data2.shape[0]\n",
    "    \n",
    "    if nchan >= 5 and nchan2 >=5 and subj!=53:\n",
    "        #print('doing')\n",
    "        for band in range(1,len(bands)):\n",
    "            nn= int((2/bands[band][0])*500)\n",
    "            low = bands[band][0]\n",
    "            high = bands[band][1]\n",
    "            filt = True\n",
    "            bb =ss.firwin(nn,[low,high],pass_zero = False, fs = 500)\n",
    "            aa = 1\n",
    "            if filt: \n",
    "                filtered = ss.filtfilt(bb,aa,data,axis =1, padlen = 500)\n",
    "            else:\n",
    "                filtered =data\n",
    "            for g in range(nchan):\n",
    "                asil,bsil,esil = dfa(np.abs(ss.hilbert(filtered[g])), scale_lim =(3,hh),overlap =  overlap, det = 1)\n",
    "                dfa_sil_params[band-1].append(np.array([asil,bsil,esil]))\n",
    "\n",
    "            if filt: \n",
    "                filtered = ss.filtfilt(bb,aa,data2,axis =1, padlen = 500)\n",
    "            else:\n",
    "                filtered = data2\n",
    "            for g in range(nchan2):\n",
    "                asil,bsil,esil = dfa(np.abs(ss.hilbert(filtered[g])), scale_lim =(3,hh),overlap =  overlap, det = 1)\n",
    "                dfa_sil2_params[band-1].append(np.array([asil,bsil,esil]))\n",
    "    \n",
    "    if nchan >= 5 and nchan2 >=5:\n",
    "        print('saving')\n",
    "        DFA_1[o] =np.array(dfa_sil_params)\n",
    "        DFA_2[o] = np.array(dfa_sil2_params)\n",
    "        o+=1\n",
    "    #if i ==0: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b680d9d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DFA_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mDFA_1\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DFA_1' is not defined"
     ]
    }
   ],
   "source": [
    "DFA_1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c02cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## in teoria dopo un tot correlazioni divrebbero convergere (come si fa in autocorr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "36e56c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22, 23, 13, 2, 29, 3, 4, 16, 5, 7, 27, 19]\n"
     ]
    }
   ],
   "source": [
    "good_sub = np.asarray(good_sub, dtype = int)\n",
    "## ORDER OF THE LANGUAGES\n",
    "order = pd.read_excel('../../../Downloads/ordine lingue.xlsx')#1 en, 2 fr, 3 sp\n",
    "\n",
    "\n",
    "subject_french = order[order[\"last language\"]==2][\"subject\"].values\n",
    "\n",
    "subject_en = order[order[\"last language\"]==1][\"subject\"].values\n",
    "\n",
    "subject_span = order[order[\"last language\"]==3][\"subject\"].values\n",
    "\n",
    "sub_fren = (list(set(subject_french) & set(good_sub)))\n",
    "sub_span = (list(set(subject_span) & set(good_sub)))\n",
    "sub_en = (list(set(subject_en) & set(good_sub)))\n",
    "\n",
    "\n",
    "good_sub = np.asarray(good_sub)\n",
    "\n",
    "#index. = np.where()\n",
    "\n",
    "type(good_sub)\n",
    "\n",
    "h = []\n",
    "for k in sub_fren:\n",
    "    #if k in good_sub:\n",
    "    #h.append(np.where(k == good_sub)[0])\n",
    "    h.append(good_sub.tolist().index(k))\n",
    "print(h)        \n",
    "#np.concatenate(h)\n",
    "\n",
    "ll = np.concatenate([np.where(good_sub==i)[0] for i in sub_fren])\n",
    "\n",
    "ll\n",
    "\n",
    "def funct(sub, vec1, vec2):\n",
    "    index = np.concatenate([np.where(good_sub==i)[0] for i in sub])\n",
    "    #index = np.where(good_sub, sub_fren)\n",
    "    al1 = vec1[index]\n",
    "    al2 = vec2[index]\n",
    "    print(stats.ttest_rel(al1, al2,alternative = 'less') )\n",
    "    \n",
    "    \n",
    "\n",
    "def funct2(sub, vec1):\n",
    "    index = np.concatenate([np.where(good_sub==i)[0] for i in sub])\n",
    "    #index = np.where(good_sub, sub_fren)\n",
    "    al1 = vec1[index]\n",
    "    #al2 = vec2[index]\n",
    "    return al1\n",
    "    #print(stats.ttest_rel(al1, al2,alternative = 'less') )\n",
    "    a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8194e213",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleans = []\n",
    "bands = [[4,8],[8,13],[14,30],[31,60]]\n",
    "xminn = np.log2( (3/np.array(bands)[:,0])*500)\n",
    "xminn[-1] = xminn[-1] + 2\n",
    "for band in range(4):\n",
    "    o = 0\n",
    "    clean = pd.DataFrame(columns = ['Silence', 'DFAexp', 'sub_id', 'ch' ],  index = np.arange(0,570,1), dtype = 'float')\n",
    "    for j in in range(len(good_sub)):\n",
    "        param =DFA_1[j]\n",
    "        ntrial = param.shape[0]\n",
    "        param = np.array(param).reshape(ntrial,3,-1)\n",
    "        dfa_sil_subjects = [[] for r in range(ntrial)]\n",
    "        for r in range(ntrial):\n",
    "            c = plot_fluct(param[r,0],param[r,1],param[r,2],xmin = xminn[band], xmax = 13.4)\n",
    "            clean.iloc[o][\"DFAexp\"] = float(c[0])\n",
    "            clean.iloc[o][\"sub_id\"]  = funct2(good_sub, good_sub)[j]\n",
    "            clean.iloc[o][\"ch\"] = int(r)\n",
    "            o+=1\n",
    "    for j in in range(len(good_sub)):\n",
    "        param =DFA_2[j]\n",
    "        ntrial = param.shape[0]\n",
    "        param = np.array(param).reshape(ntrial,3,-1)\n",
    "        dfa_sil_subjects = [[] for r in range(ntrial)]\n",
    "        for r in range(ntrial):\n",
    "            c = plot_fluct(param[r,0],param[r,1],param[r,2],xmin = xminn[band], xmax = 13.4)\n",
    "            clean.iloc[o][\"DFAexp\"] = float(c[0])\n",
    "            clean.iloc[o][\"sub_id\"]  = funct2(good_sub, good_sub)[j]\n",
    "            clean.iloc[o][\"ch\"] = int(r)\n",
    "            o+=1\n",
    "    \n",
    "    clean[\"Silence\"] = [\"1\" for r in range(275) ]+ [\"2\" for r in range(295)]\n",
    "    cleans.append(clean)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48eee04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benedetta\\AppData\\Local\\Temp\\ipykernel_16304\\1929512027.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tau1s = np.asarray(tau1s)\n",
      "C:\\Users\\Benedetta\\AppData\\Local\\Temp\\ipykernel_16304\\1929512027.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tau2s = np.asarray(tau2s)\n"
     ]
    }
   ],
   "source": [
    "tau1s = np.asarray(tau1s)\n",
    "tau2s = np.asarray(tau2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ff88c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benedetta\\AppData\\Local\\Temp\\ipykernel_16304\\277544956.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr1 = np.asarray([t1_frenc, t1_span, t1_en])\n",
      "C:\\Users\\Benedetta\\AppData\\Local\\Temp\\ipykernel_16304\\277544956.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr2 = np.asarray([t2_frenc, t2_span, t2_en]) ##\n"
     ]
    }
   ],
   "source": [
    "t1_frenc = funct2(sub_fren, tau1s)\n",
    "t1_span = funct2(sub_span, tau1s)\n",
    "t1_en= funct2(sub_en, tau1s)\n",
    "\n",
    "t2_frenc = funct2(sub_fren, tau2s)\n",
    "t2_span = funct2(sub_span, tau2s)\n",
    "t2_en= funct2(sub_en, tau2s)\n",
    "\n",
    "arr1 = np.asarray([t1_frenc, t1_span, t1_en])\n",
    "arr2 = np.asarray([t2_frenc, t2_span, t2_en]) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92da7366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 0\n",
    "for i in t1_frenc:\n",
    "    a+= len(i)\n",
    "print(a)\n",
    "\n",
    "#a = 0\n",
    "for i in t2_frenc:\n",
    "    a+= len(i)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f8df737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221\n"
     ]
    }
   ],
   "source": [
    "o = 0\n",
    "df_fren = pd.DataFrame(columns = ['Silence', 'tau_c', 'sub_id', 'ch' ],  index = np.arange(0,221,1), dtype = 'float')\n",
    "for j in range(len(t1_frenc)):\n",
    "    ntrial = len(t1_frenc[j])\n",
    "    for r in range(ntrial):\n",
    "        df_fren.iloc[o][\"tau_c\"] = float(t1_frenc[j][r])\n",
    "        df_fren.iloc[o][\"sub_id\"]  = funct2(sub_fren, good_sub)[j]\n",
    "        df_fren.iloc[o][\"ch\"] = int(r)\n",
    "        o+=1\n",
    "        \n",
    "        \n",
    "for j in range(len(t2_frenc)):\n",
    "    ntrial = len(t2_frenc[j])\n",
    "    for r in range(ntrial):\n",
    "        df_fren.iloc[o][\"tau_c\"] = float(t2_frenc[j][r])\n",
    "        df_fren.iloc[o][\"sub_id\"]  = funct2(sub_fren, good_sub)[j]\n",
    "        df_fren.iloc[o][\"ch\"] = int(r)\n",
    "        o+=1\n",
    "print(o)\n",
    "df_fren[\"Silence\"] = [\"1\" for r in range(113) ]+ [\"2\" for r in range(108)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bbe134",
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8e436c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278\n",
      "574 296\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "for i in t1_span:\n",
    "    a+= len(i)\n",
    "print(a)\n",
    "c = a\n",
    "#a = 0\n",
    "for i in t2_span:\n",
    "    a+= len(i)\n",
    "print(a, a-c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14945e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "for i in tau1s:\n",
    "    a+= len(i)\n",
    "print(a)\n",
    "c = a\n",
    "#a = 0\n",
    "for i in tau2s:\n",
    "    a+= len(i)\n",
    "print(a, a-c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "181b08f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "574\n"
     ]
    }
   ],
   "source": [
    "o = 0\n",
    "df_total = pd.DataFrame(columns = ['Silence', 'tau_c', 'sub_id', 'ch' ],  index = np.arange(0,574,1), dtype = 'float')\n",
    "for j in range(len(tau1s)):\n",
    "    ntrial = len(tau1s[j])\n",
    "    for r in range(ntrial):\n",
    "        df_total.iloc[o][\"tau_c\"] = float(tau1s[j][r])\n",
    "        df_total.iloc[o][\"sub_id\"]  = funct2(good_sub, good_sub)[j]\n",
    "        df_total.iloc[o][\"ch\"] = int(r)\n",
    "        o+=1\n",
    "        \n",
    "        \n",
    "for j in range(len(tau2s)):\n",
    "    ntrial = len(tau2s[j])\n",
    "    for r in range(ntrial):\n",
    "        df_total.iloc[o][\"tau_c\"] = float(tau2s[j][r])\n",
    "        df_total.iloc[o][\"sub_id\"]  = funct2(good_sub, good_sub)[j]\n",
    "        df_total.iloc[o][\"ch\"] = int(r)\n",
    "        o+=1\n",
    "print(o)\n",
    "df_total[\"Silence\"] = [\"1\" for r in range(278) ]+ [\"2\" for r in range(296)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc06aca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "640"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*10*2, #missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fbd7917e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Mixed Linear Model Regression Results\n",
      "===================================================================\n",
      "Model:                 MixedLM     Dependent Variable:     tau_c   \n",
      "No. Observations:      574         Method:                 REML    \n",
      "No. Groups:            32          Scale:                  0.0035  \n",
      "Min. group size:       14          Log-Likelihood:         725.6966\n",
      "Max. group size:       20          Converged:              Yes     \n",
      "Mean group size:       17.9                                        \n",
      "-------------------------------------------------------------------\n",
      "                         Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "-------------------------------------------------------------------\n",
      "Intercept                 0.283    0.010 27.765 0.000  0.263  0.303\n",
      "Silence[T.2]              0.007    0.013  0.544 0.586 -0.019  0.033\n",
      "Group Var                 0.003    0.015                           \n",
      "Group x Silence[T.2] Cov -0.001    0.014                           \n",
      "Silence[T.2] Var          0.005    0.025                           \n",
      "===================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benedetta\\anaconda3\\lib\\site-packages\\statsmodels\\regression\\mixed_linear_model.py:2237: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "md = smf.mixedlm(\"tau_c ~Silence\", df_total, groups=df_total[\"sub_id\"], re_formula=\"~Silence\") ### riscalando per i canali \n",
    "# mixed model tenendo conto di identità di canali....\n",
    "mdf = md.fit(method=[\"lbfgs\"])\n",
    "print(mdf.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b103f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "for i in t1_span:\n",
    "    a+= len(i)\n",
    "print(a)\n",
    "c = a\n",
    "#a = 0\n",
    "for i in t2_span:\n",
    "    a+= len(i)\n",
    "print(a, a-c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c245920f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n"
     ]
    }
   ],
   "source": [
    "o = 0\n",
    "df_span = pd.DataFrame(columns = ['Silence', 'tau_c', 'sub_id', 'ch' ],  index = np.arange(0,164,1), dtype = 'float')\n",
    "for j in range(len(t1_span)):\n",
    "    ntrial = len(t1_span[j])\n",
    "    for r in range(ntrial):\n",
    "        df_span.iloc[o][\"tau_c\"] = float(t1_span[j][r])\n",
    "        df_span.iloc[o][\"sub_id\"]  = funct2(sub_span, good_sub)[j]\n",
    "        df_span.iloc[o][\"ch\"] = int(r)\n",
    "        o+=1\n",
    "        \n",
    "        \n",
    "for j in range(len(t2_span)):\n",
    "    ntrial = len(t2_span[j])\n",
    "    for r in range(ntrial):\n",
    "        df_span.iloc[o][\"tau_c\"] = float(t2_span[j][r])\n",
    "        df_span.iloc[o][\"sub_id\"]  = funct2(sub_span, good_sub)[j]\n",
    "        df_span.iloc[o][\"ch\"] = int(r)\n",
    "        o+=1\n",
    "print(o)\n",
    "df_span[\"Silence\"] = [\"1\" for r in range(76) ]+ [\"2\" for r in range(88)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12574a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18fa1bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5f36fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f50d7ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fren.to_csv(\"../../../Desktop/Criticality in barrel cortex/EEG avalanche analysis/tau_fren_2ndmeth.csv\", index = True)\n",
    "df_span.to_csv(\"../../../Desktop/Criticality in barrel cortex/EEG avalanche analysis/tau_span_2ndmeth.csv\", index = True)\n",
    "df_en.to_csv(\"../../../Desktop/Criticality in barrel cortex/EEG avalanche analysis/tau_en_2ndmeth.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "46690bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Silence</th>\n",
       "      <th>tau_c</th>\n",
       "      <th>sub_id</th>\n",
       "      <th>ch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.542652</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.518412</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.424604</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.371044</td>\n",
       "      <td>66.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.370191</td>\n",
       "      <td>66.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>2</td>\n",
       "      <td>0.487911</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>2</td>\n",
       "      <td>0.448473</td>\n",
       "      <td>56.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>2</td>\n",
       "      <td>0.477559</td>\n",
       "      <td>56.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>2</td>\n",
       "      <td>0.503569</td>\n",
       "      <td>56.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>2</td>\n",
       "      <td>0.534939</td>\n",
       "      <td>56.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Silence     tau_c  sub_id   ch\n",
       "0          1  0.542652    66.0  0.0\n",
       "1          1  0.518412    66.0  1.0\n",
       "2          1  0.424604    66.0  2.0\n",
       "3          1  0.371044    66.0  3.0\n",
       "4          1  0.370191    66.0  4.0\n",
       "..       ...       ...     ...  ...\n",
       "216        2  0.487911    56.0  4.0\n",
       "217        2  0.448473    56.0  5.0\n",
       "218        2  0.477559    56.0  6.0\n",
       "219        2  0.503569    56.0  7.0\n",
       "220        2  0.534939    56.0  8.0\n",
       "\n",
       "[221 rows x 4 columns]"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"../../../Desktop/Criticality in barrel cortex/EEG avalanche analysis/fren.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31ad1b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Mixed Linear Model Regression Results\n",
      "===================================================================\n",
      "Model:                 MixedLM     Dependent Variable:     tau_c   \n",
      "No. Observations:      164         Method:                 REML    \n",
      "No. Groups:            9           Scale:                  0.0044  \n",
      "Min. group size:       16          Log-Likelihood:         187.6310\n",
      "Max. group size:       20          Converged:              Yes     \n",
      "Mean group size:       18.2                                        \n",
      "-------------------------------------------------------------------\n",
      "                         Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "-------------------------------------------------------------------\n",
      "Intercept                 0.291    0.017 17.396 0.000  0.258  0.323\n",
      "Silence[T.2]              0.023    0.028  0.821 0.411 -0.032  0.078\n",
      "Group Var                 0.002    0.019                           \n",
      "Group x Silence[T.2] Cov -0.000    0.023                           \n",
      "Silence[T.2] Var          0.006    0.056                           \n",
      "===================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benedetta\\anaconda3\\lib\\site-packages\\statsmodels\\regression\\mixed_linear_model.py:2237: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "md = smf.mixedlm(\"tau_c ~Silence\", df_span, groups=df_span[\"sub_id\"], re_formula=\"~Silence\") ### riscalando per i canali \n",
    "# mixed model tenendo conto di identità di canali....\n",
    "mdf = md.fit(method=[\"lbfgs\"])\n",
    "print(mdf.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b2af38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Mixed Linear Model Regression Results\n",
      "===================================================================\n",
      "Model:                 MixedLM     Dependent Variable:     tau_c   \n",
      "No. Observations:      189         Method:                 REML    \n",
      "No. Groups:            11          Scale:                  0.0023  \n",
      "Min. group size:       14          Log-Likelihood:         274.3412\n",
      "Max. group size:       20          Converged:              Yes     \n",
      "Mean group size:       17.2                                        \n",
      "-------------------------------------------------------------------\n",
      "                         Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "-------------------------------------------------------------------\n",
      "Intercept                 0.301    0.019 16.018 0.000  0.265  0.338\n",
      "Silence[T.2]             -0.027    0.018 -1.510 0.131 -0.061  0.008\n",
      "Group Var                 0.004    0.038                           \n",
      "Group x Silence[T.2] Cov -0.002    0.029                           \n",
      "Silence[T.2] Var          0.003    0.032                           \n",
      "===================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benedetta\\anaconda3\\lib\\site-packages\\statsmodels\\regression\\mixed_linear_model.py:2237: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "md = smf.mixedlm(\"tau_c ~Silence\", df_en, groups=df_en[\"sub_id\"], re_formula=\"~Silence\") ### riscalando per i canali \n",
    "# mixed model tenendo conto di identità di canali....\n",
    "mdf = md.fit(method=[\"lbfgs\"])\n",
    "print(mdf.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61888b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Mixed Linear Model Regression Results\n",
      "===================================================================\n",
      "Model:                 MixedLM     Dependent Variable:     tau_c   \n",
      "No. Observations:      221         Method:                 REML    \n",
      "No. Groups:            12          Scale:                  0.0039  \n",
      "Min. group size:       16          Log-Likelihood:         266.5707\n",
      "Max. group size:       20          Converged:              Yes     \n",
      "Mean group size:       18.4                                        \n",
      "-------------------------------------------------------------------\n",
      "                         Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "-------------------------------------------------------------------\n",
      "Intercept                 0.262    0.016 15.889 0.000  0.229  0.294\n",
      "Silence[T.2]              0.026    0.022  1.154 0.249 -0.018  0.069\n",
      "Group Var                 0.003    0.023                           \n",
      "Group x Silence[T.2] Cov -0.001    0.022                           \n",
      "Silence[T.2] Var          0.005    0.042                           \n",
      "===================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benedetta\\anaconda3\\lib\\site-packages\\statsmodels\\regression\\mixed_linear_model.py:2237: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "md = smf.mixedlm(\"tau_c ~Silence\", df_fren, groups=df_fren[\"sub_id\"], re_formula=\"~Silence\") ### riscalando per i canali \n",
    "# mixed model tenendo conto di identità di canali....\n",
    "mdf = md.fit(method=[\"lbfgs\"])\n",
    "print(mdf.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd28e281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 0\n",
    "for i in t1_en:\n",
    "    a+= len(i)\n",
    "print(a)\n",
    "\n",
    "#a = 0\n",
    "for i in t2_en:\n",
    "    a+= len(i)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "d3a10358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=1.2080650160523068, pvalue=0.12740772526048091, df=10)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as stats \n",
    "\n",
    "stats.ttest_rel(t1_en, t2_en, alternative = 'greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "b7546c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t1_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943f9e55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
